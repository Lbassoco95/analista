"""
Analizador optimizado principal que integra Hugging Face Transformers, Safetensors y GPT.
Implementa principios de desarrollo robusto basados en las mejores pr√°cticas.
"""

import os
import json
import asyncio
from typing import Dict, List, Any, Optional
from datetime import datetime
import logging
import sys

# Agregar el directorio actual al path para importar m√≥dulos
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from supabase_client import SupabaseManager
from utils.optimized_analyzer import OptimizedAnalyzer
from dotenv import load_dotenv

# Cargar variables de entorno
load_dotenv()

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class OptimizedGPTAnalyzer:
    """
    Analizador GPT optimizado que combina modelos locales de Hugging Face
    con an√°lisis GPT para m√°xima eficiencia y precisi√≥n.
    """
    
    def __init__(self, use_local_models: bool = True, use_gpt: bool = True):
        """
        Inicializar el analizador optimizado.
        
        Args:
            use_local_models: Si usar modelos locales de Hugging Face
            use_gpt: Si usar an√°lisis GPT como respaldo
        """
        self.supabase_manager = SupabaseManager()
        self.optimized_analyzer = OptimizedAnalyzer(use_local_models, use_gpt)
        
        logger.info("Optimized GPT Analyzer initialized successfully")
    
    async def analyze_all_data_optimized(self, limit: Optional[int] = None) -> Dict[str, Any]:
        """
        Analizar todos los datos usando estrategia optimizada.
        
        Args:
            limit: L√≠mite de registros a procesar
            
        Returns:
            Estad√≠sticas del an√°lisis
        """
        logger.info("üöÄ Iniciando an√°lisis optimizado de todos los datos...")
        
        # Obtener datos no analizados
        unanalyzed_data = self.get_unanalyzed_data()
        
        if limit:
            unanalyzed_data = unanalyzed_data[:limit]
        
        if not unanalyzed_data:
            logger.info("‚úÖ No hay datos para analizar")
            return {"procesados": 0, "exitosos": 0, "fallidos": 0}
        
        stats = {
            "procesados": len(unanalyzed_data),
            "exitosos": 0,
            "fallidos": 0,
            "analysis_methods": {},
            "performance_metrics": {}
        }
        
        # Preparar datos para an√°lisis en lote
        texts_for_analysis = []
        for record in unanalyzed_data:
            texts_for_analysis.append({
                'text': record['texto_extraido'],
                'source': record['fuente'],
                'record_id': record['id']
            })
        
        # An√°lisis en lote optimizado
        start_time = datetime.now()
        analysis_results = await self.optimized_analyzer.analyze_batch_optimized(texts_for_analysis)
        end_time = datetime.now()
        
        # Procesar resultados y actualizar Supabase
        for i, (text_data, analysis_result) in enumerate(zip(texts_for_analysis, analysis_results)):
            try:
                # Actualizar registro en Supabase
                if self.update_record_with_analysis(text_data['record_id'], analysis_result):
                    stats["exitosos"] += 1
                    
                    # Contar m√©todos de an√°lisis utilizados
                    method = analysis_result.get("analysis_method", "unknown")
                    stats["analysis_methods"][method] = stats["analysis_methods"].get(method, 0) + 1
                else:
                    stats["fallidos"] += 1
                
                logger.info(f"‚úÖ Procesado registro {i+1}/{len(unanalyzed_data)} (ID: {text_data['record_id']})")
                
            except Exception as e:
                logger.error(f"‚ùå Error procesando registro {text_data['record_id']}: {str(e)}")
                stats["fallidos"] += 1
        
        # Calcular m√©tricas de rendimiento
        processing_time = (end_time - start_time).total_seconds()
        stats["performance_metrics"] = {
            "total_time_seconds": processing_time,
            "average_time_per_record": processing_time / len(unanalyzed_data) if unanalyzed_data else 0,
            "records_per_second": len(unanalyzed_data) / processing_time if processing_time > 0 else 0
        }
        
        logger.info(f"\nüìä An√°lisis optimizado completado:")
        logger.info(f"   - Procesados: {stats['procesados']}")
        logger.info(f"   - Exitosos: {stats['exitosos']}")
        logger.info(f"   - Fallidos: {stats['fallidos']}")
        logger.info(f"   - Tiempo total: {processing_time:.2f} segundos")
        logger.info(f"   - M√©todos utilizados: {stats['analysis_methods']}")
        
        return stats
    
    def get_unanalyzed_data(self) -> List[Dict[str, Any]]:
        """
        Obtener datos no analizados de Supabase.
        
        Returns:
            Lista de registros sin an√°lisis
        """
        try:
            # Buscar registros que no tengan an√°lisis
            response = self.supabase_manager.client.table('precios_modulos').select('*').execute()
            
            # Filtrar registros que no tengan an√°lisis GPT
            unanalyzed = []
            for record in response.data:
                # Verificar si ya fue analizado
                if not record.get('analizado_gpt', False):
                    unanalyzed.append(record)
            
            logger.info(f"üìä Encontrados {len(unanalyzed)} registros para analizar")
            return unanalyzed
            
        except Exception as e:
            logger.error(f"‚ùå Error obteniendo datos de Supabase: {str(e)}")
            return []
    
    def update_record_with_analysis(self, record_id: int, analysis: Dict[str, Any]) -> bool:
        """
        Actualizar registro en Supabase con el an√°lisis optimizado.
        
        Args:
            record_id: ID del registro a actualizar
            analysis: An√°lisis optimizado
            
        Returns:
            True si se actualiz√≥ correctamente
        """
        try:
            update_data = {
                'precio_gpt': analysis.get('precio_estimado'),
                'clasificacion_gpt': analysis.get('clasificacion_modulo'),
                'condiciones_comerciales': json.dumps(analysis.get('condiciones_comerciales', {})),
                'confianza_analisis': analysis.get('confianza_analisis'),
                'fecha_analisis_gpt': datetime.now().isoformat(),
                'analizado_gpt': True,
                'metodo_analisis': analysis.get('analysis_method', 'unknown')
            }
            
            response = self.supabase_manager.client.table('precios_modulos').update(update_data).eq('id', record_id).execute()
            
            logger.debug(f"‚úÖ Registro {record_id} actualizado con an√°lisis optimizado")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error actualizando registro {record_id}: {str(e)}")
            return False
    
    async def test_analysis_pipeline(self) -> Dict[str, Any]:
        """
        Probar el pipeline de an√°lisis con datos de ejemplo.
        
        Returns:
            Resultados de la prueba
        """
        logger.info("üß™ Probando pipeline de an√°lisis optimizado...")
        
        test_texts = [
            {
                'text': 'B2Broker offers comprehensive white label solutions for crypto exchanges. Setup fee starts at $50,000 with monthly maintenance costs of $5,000.',
                'source': 'B2Broker Test'
            },
            {
                'text': 'Sumsub provides KYC verification services with AI-powered identity verification. Pricing starts at $0.50 per verification.',
                'source': 'Sumsub Test'
            },
            {
                'text': 'Wallester offers secure digital wallet solution with advanced encryption. Monthly subscription costs $2,500.',
                'source': 'Wallester Test'
            }
        ]
        
        try:
            # An√°lisis en lote
            results = await self.optimized_analyzer.analyze_batch_optimized(test_texts)
            
            # Mostrar resultados
            logger.info("üìã Resultados de la prueba:")
            for i, (test_data, result) in enumerate(zip(test_texts, results)):
                logger.info(f"  Test {i+1} ({test_data['source']}):")
                logger.info(f"    - M√©todo: {result.get('analysis_method', 'unknown')}")
                logger.info(f"    - Clasificaci√≥n: {result.get('clasificacion_modulo', 'N/A')}")
                logger.info(f"    - Precio: {result.get('precio_estimado', 'N/A')}")
                logger.info(f"    - Confianza: {result.get('confianza_analisis', 'N/A')}")
            
            return {
                "success": True,
                "results": results,
                "stats": self.optimized_analyzer.get_analysis_stats()
            }
            
        except Exception as e:
            logger.error(f"‚ùå Error en prueba de pipeline: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def get_system_stats(self) -> Dict[str, Any]:
        """
        Obtener estad√≠sticas completas del sistema.
        
        Returns:
            Estad√≠sticas del sistema
        """
        stats = {
            "timestamp": datetime.now().isoformat(),
            "analyzer_stats": self.optimized_analyzer.get_analysis_stats(),
            "supabase_connection": self.supabase_manager.test_connection(),
            "system_info": {
                "python_version": sys.version,
                "platform": sys.platform,
                "cpu_count": os.cpu_count()
            }
        }
        
        return stats
    
    def optimize_system(self):
        """Optimizar el sistema de an√°lisis."""
        logger.info("üîß Optimizando sistema de an√°lisis...")
        
        # Optimizar cache
        self.optimized_analyzer.optimize_cache()
        
        # Limpiar memoria si es necesario
        import gc
        gc.collect()
        
        logger.info("‚úÖ Sistema optimizado")

async def main():
    """Funci√≥n principal del analizador optimizado."""
    import argparse
    
    parser = argparse.ArgumentParser(description='Analizador GPT Optimizado con Hugging Face')
    parser.add_argument('--limit', type=int, help='L√≠mite de registros a procesar')
    parser.add_argument('--test', action='store_true', help='Ejecutar prueba del pipeline')
    parser.add_argument('--local-only', action='store_true', help='Usar solo modelos locales')
    parser.add_argument('--gpt-only', action='store_true', help='Usar solo GPT')
    parser.add_argument('--stats', action='store_true', help='Mostrar estad√≠sticas del sistema')
    
    args = parser.parse_args()
    
    logger.info("üß† Analizador GPT Optimizado con Hugging Face")
    logger.info("=" * 60)
    
    try:
        # Configurar modo de an√°lisis
        use_local = not args.gpt_only
        use_gpt = not args.local_only
        
        analyzer = OptimizedGPTAnalyzer(use_local_models=use_local, use_gpt=use_gpt)
        
        if args.test:
            # Prueba del pipeline
            result = await analyzer.test_analysis_pipeline()
            if result["success"]:
                logger.info("‚úÖ Prueba del pipeline exitosa")
            else:
                logger.error(f"‚ùå Prueba del pipeline fallida: {result.get('error')}")
        
        elif args.stats:
            # Mostrar estad√≠sticas
            stats = analyzer.get_system_stats()
            logger.info("üìä Estad√≠sticas del sistema:")
            logger.info(json.dumps(stats, indent=2, ensure_ascii=False))
        
        else:
            # An√°lisis completo
            stats = await analyzer.analyze_all_data_optimized(args.limit)
            logger.info(f"üéâ An√°lisis optimizado completado con √©xito!")
            
            # Optimizar sistema despu√©s del an√°lisis
            analyzer.optimize_system()
            
    except Exception as e:
        logger.error(f"‚ùå Error en el analizador optimizado: {str(e)}")
        logger.info("üí° Verifica que tengas las dependencias instaladas y las credenciales configuradas")

if __name__ == "__main__":
    asyncio.run(main()) 